{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ossscot0ZtD",
        "outputId": "6e784c69-7fff-4129-f6a1-38cf8d3a87a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-11 14:48:39--  https://raw.githubusercontent.com/santoshdahal2016/GPT-from-scratch/main/munamadan.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 108544 (106K) [text/plain]\n",
            "Saving to: ‘munamadan.txt’\n",
            "\n",
            "munamadan.txt       100%[===================>] 106.00K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-02-11 14:48:40 (5.09 MB/s) - ‘munamadan.txt’ saved [108544/108544]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/santoshdahal2016/GPT-from-scratch/main/munamadan.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('munamadan.txt', 'r')\n",
        "text = f.read()\n",
        "\n",
        "print(text[:100])\n",
        "\n",
        "characters = sorted(set(list(text)))\n",
        "\n",
        "print(characters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LPDNMig05wi",
        "outputId": "6e558849-798e-4c83-b5f7-42db137e8aa5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "है मेरा भाइ ! हे मेरा बहिनी ! पहाड शहरमा,\n",
            "यो यौटा मैरो भक्तिको माला चढाएँ चरणमा ।\n",
            "अरू ता मैले के गर्\n",
            "['\\n', ' ', '!', '\"', '&', \"'\", ',', '-', '.', '1', '4', ':', ';', '?', '|', '«', '»', 'ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ए', 'ऐ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'े', 'ै', 'ो', 'ौ', '्', '॑', '॒', '।', '॥', '०', '३', '७', '\\u200c', '“', '”']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = { ch:i for i , ch in enumerate(characters)}\n",
        "iots = { i:ch for i , ch in enumerate(characters)}\n",
        "\n",
        "encode = lambda s: [ stoi[c] for c in s]\n",
        "decode = lambda i: ''.join([ iots[c] for c in i])"
      ],
      "metadata": {
        "id": "trVDCVuI2J8h"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encode(\"है मेरा भाइ\"))\n",
        "# print(decode(0))\n",
        "\n",
        "print(iots[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWNp8Zn-26Bx",
        "outputId": "7b66dfc6-4ebf-405a-de3d-19ccbd9fae83"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[61, 69, 1, 53, 68, 55, 62, 1, 52, 62, 22]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "\n",
        "print(data.shape, data.dtype)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t14ho1cc3U-n",
        "outputId": "87f7fdcf-2233-4ad8-95aa-abaedd0f152a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([42166]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9 * len(data))\n",
        "\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "print(train_data[:20])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0W5HieJ4BX8",
        "outputId": "d60cba67-0fcd-4aa5-9e6b-32e6836fba8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([61, 69,  1, 53, 68, 55, 62,  1, 52, 62, 22,  1,  2,  1, 61, 68,  1, 53,\n",
            "        68, 55])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "\n",
        "for t in range(block_size):\n",
        "  print(x[:t+1] , y[t])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI4Dad1kE3-A",
        "outputId": "19a2a1cd-570e-43f0-8331-58402ba992b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([61]) tensor(69)\n",
            "tensor([61, 69]) tensor(1)\n",
            "tensor([61, 69,  1]) tensor(53)\n",
            "tensor([61, 69,  1, 53]) tensor(68)\n",
            "tensor([61, 69,  1, 53, 68]) tensor(55)\n",
            "tensor([61, 69,  1, 53, 68, 55]) tensor(62)\n",
            "tensor([61, 69,  1, 53, 68, 55, 62]) tensor(1)\n",
            "tensor([61, 69,  1, 53, 68, 55, 62,  1]) tensor(52)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "\n",
        "def get_batch(split):\n",
        "  data =  train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack( [ data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack( [ data[i+1:i+block_size+1] for i in ix])\n",
        "  \n",
        "  return x, y\n"
      ],
      "metadata": {
        "id": "jNqj2qLsFZGN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xa,ya = get_batch('train')\n",
        "\n",
        "print(xa.shape, ya.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbkEDN4KNe17",
        "outputId": "3beabd80-6db7-4da2-f7d3-4bd5d2aa8ad2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8]) torch.Size([4, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(batch_size):\n",
        "  for j in range(block_size):\n",
        "    print(xa[i ,:j + 1] , ya[i , j])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66Of3iKhO1nn",
        "outputId": "20783d21-cbb7-4376-b2b4-4081a9b2b3af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([63]) tensor(49)\n",
            "tensor([63, 49]) tensor(53)\n",
            "tensor([63, 49, 53]) tensor(62)\n",
            "tensor([63, 49, 53, 62]) tensor(6)\n",
            "tensor([63, 49, 53, 62,  6]) tensor(0)\n",
            "tensor([63, 49, 53, 62,  6,  0]) tensor(57)\n",
            "tensor([63, 49, 53, 62,  6,  0, 57]) tensor(69)\n",
            "tensor([63, 49, 53, 62,  6,  0, 57, 69]) tensor(56)\n",
            "tensor([56]) tensor(70)\n",
            "tensor([56, 70]) tensor(1)\n",
            "tensor([56, 70,  1]) tensor(50)\n",
            "tensor([56, 70,  1, 50]) tensor(65)\n",
            "tensor([56, 70,  1, 50, 65]) tensor(55)\n",
            "tensor([56, 70,  1, 50, 65, 55]) tensor(72)\n",
            "tensor([56, 70,  1, 50, 65, 55, 72]) tensor(50)\n",
            "tensor([56, 70,  1, 50, 65, 55, 72, 50]) tensor(65)\n",
            "tensor([62]) tensor(33)\n",
            "tensor([62, 33]) tensor(72)\n",
            "tensor([62, 33, 72]) tensor(80)\n",
            "tensor([62, 33, 72, 80]) tensor(1)\n",
            "tensor([62, 33, 72, 80,  1]) tensor(34)\n",
            "tensor([62, 33, 72, 80,  1, 34]) tensor(53)\n",
            "tensor([62, 33, 72, 80,  1, 34, 53]) tensor(72)\n",
            "tensor([62, 33, 72, 80,  1, 34, 53, 72]) tensor(29)\n",
            "tensor([1]) tensor(45)\n",
            "tensor([ 1, 45]) tensor(64)\n",
            "tensor([ 1, 45, 64]) tensor(1)\n",
            "tensor([ 1, 45, 64,  1]) tensor(35)\n",
            "tensor([ 1, 45, 64,  1, 35]) tensor(70)\n",
            "tensor([ 1, 45, 64,  1, 35, 70]) tensor(55)\n",
            "tensor([ 1, 45, 64,  1, 35, 70, 55]) tensor(64)\n",
            "tensor([ 1, 45, 64,  1, 35, 70, 55, 64]) tensor(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class BiagramLanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, idx ,targets=None):\n",
        "\n",
        "    logits = self.token_embedding_table(idx)\n",
        "\n",
        "    if targets == None:\n",
        "      loss = None\n",
        "    else: \n",
        "      B , T , C = logits.shape\n",
        "\n",
        "      logits = logits.view(B*T , C)\n",
        "      targets = targets.view(B*T)\n",
        "\n",
        "      loss = F.cross_entropy(logits , targets)\n",
        "\n",
        "    return logits , loss\n",
        "\n",
        "  def generate(self , idx , max_new_tokens):\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "      logits, loss = self(idx)\n",
        "      logits = logits[:, -1, :]\n",
        "      probs = F.softmax(logits, dim = -1)\n",
        "\n",
        "      idx_next = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "      idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "\n",
        "vocab_size = len(characters)\n",
        "m = BiagramLanguageModel(vocab_size)\n",
        "\n",
        "logits , loss = m(xa, ya)\n",
        "\n",
        "print(logits.shape, loss )\n",
        "\n",
        "# print(decode(torch.zeros((1, 1), dtype=torch.long)))\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l96vUJ8VPolD",
        "outputId": "03ea0c83-7a69-4a98-eff8-4beacd65ca7e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 83]) tensor(4.8413, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "णरऔट,ं!!फिथ\"०»|भँठ|७शढई\"ईत्;ँंध:फं:य॥डई,तणौआङँइ'श«य1क4ग ए\n",
            "”॒1ए,बकः्खटजथय३1।ण1ृ\n",
            "ै॒षय:व'ौ०\n",
            "आ'शठबौ4च,॒ढ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "\n",
        "batch_size = 32\n",
        "for steps in range(10000): # increase number of steps for good results... \n",
        "    \n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en-XChOHHsuN",
        "outputId": "6c8d5172-2c83-4ddf-94d3-8c1b0ea2e94d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5181121826171875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmTfzgToHxBL",
        "outputId": "0ed66c84-0b68-40ae-d537-80f9077618a5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "छुखकोपा बूनिलरी!\n",
            "क हेरोलड्ननी जी सबती गै,\n",
            "चौ हल्‌ब्‌ सोरा,\n",
            "न्जन त,\n",
            "मी\n",
            "सौ भनेर ज्न्‌ तिमनेखाङ्नकाचन अँफूर,\n",
            "छै ! तियारप्जी प्दै माढा भै नैनमाकेरी,\n",
            "रो,\n",
            "प्यो लेशमाथेटा सहुट्‌ साईश्थली फु्यो उनैनमाउनहेको,\n",
            "मौ साराले-धायौथिबिमाले तली भिलेखा नैनैनलेर,\n",
            "भनै त्कालेरासावज हे,\n",
            "को वपायजा! सन्छै श ।”\n",
            "माकोमाइरतीपि पानैमुदेरकने न्र न तीत्गयो तिलोचागमाँडासुन, भिँधी, ?”\n",
            "वी,\n",
            "ख्र्रकोटा छो र भन, नलैलको आयोई भइनैशा नेप्‌ म भुने नायनजमा ह चमनीहा !”\n",
            "\n",
            "आमनछि छ दार त्दहौ ति दुँसा,\n",
            "प्कोमनैलाई थैँडी आँकोस्काल्तै भनक्र्छ छ,\n",
            "आ\n"
          ]
        }
      ]
    }
  ]
}